{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Syntax, Semantics, Parsing and Formal Grammars"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Syntax vs Semantics\n",
    "\n",
    "Syntax and semantics are two fundamental aspects of any programming language that help in understanding how programs are constructed and what they mean.\n",
    "\n",
    "### Syntax\n",
    "Syntax refers to the set of rules that specifies the correct combined sequence of symbols that can be used to form a correctly structured program using a specific programming language. These rules dictate how statements and expressions are formed. For example, in Python:\n",
    "\n",
    "\n",
    "- A statement to assign a value to a variable has the syntax: `variable_name = value`\n",
    "- A for-loop has the syntax: `for variable in iterable:`\n",
    "\n",
    "These rules ensure that the program is grammatically correct.\n",
    "\n",
    "Common syntax errors include:\n",
    "\n",
    "\n",
    "- Missing or extra braces, brackets, or parentheses\n",
    "- Incorrect indentation (especially in languages like Python)\n",
    "- Missing semicolons in languages where they are required (like C, C++, and Java)\n",
    "\n",
    "### Semantics\n",
    "Semantics refers to the meaning associated with syntactically valid strings of symbols in a programming language. Even if your code is syntactically correct, it might not do what you intend due to semantic errors. The semantics of a language provide the rules for interpretation of the syntax, which makes it possible for a machine to execute the code written by a developer.\n",
    "\n",
    "Examples of semantic elements in a language might include:\n",
    "\n",
    "\n",
    "- Variable scoping rules (e.g., global vs. local scope)\n",
    "- Type systems (e.g., how different data types interact)\n",
    "- Evaluation of expressions (e.g., order of operations)\n",
    "\n",
    "Common semantic errors include:\n",
    "\n",
    "\n",
    "- Type mismatch (e.g., trying to add a string and an integer)\n",
    "- Undefined variables\n",
    "- Division by zero\n",
    "- Index out of range\n",
    "\n",
    "### Relation between Syntax and Semantics\n",
    "Syntax and semantics are closely related but distinct:\n",
    "\n",
    "\n",
    "- A program could be syntactically correct but semantically wrong. For example, dividing by zero is usually syntactically correct but semantically incorrect.\n",
    "- Conversely, semantics can't be correct if the syntax is incorrect; a program won't run if it's not syntactically correct.\n",
    "\n",
    "Programming languages often come with a formal specification that details their syntax and semantics, which is essential for compiler and interpreter writers. Programmers generally don't have to study these formal specifications; they learn the rules more implicitly through documentation, tutorials, and examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Going from Source Code to Machine Code\n",
    "\n",
    "Process of going from programming language code to machine code involves multiple stages, each with its own set of tasks and objectives. \n",
    "\n",
    "### 1. Preprocessing\n",
    "This is the first stage for some languages like C and C++. The preprocessor handles tasks like macro expansion, file inclusion, conditional compilation, etc. Source code is manipulated based on preprocessor directives like `#include`, `#define`, and others.\n",
    "\n",
    "### 2. Lexical Analysis (Lexing)\n",
    "#### Objective:\n",
    "To convert the input source code into a stream of tokens. A token is a sequence of characters that represents a fundamental building block of the language, such as an identifier, a keyword, or an operator.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- The lexer scans the source code character by character.\n",
    "- It groups characters into tokens according to the lexical rules of the language.\n",
    "- Comments and white spaces are often discarded.\n",
    "\n",
    "### 3. Syntax Analysis (Parsing)\n",
    "#### Objective:\n",
    "To convert the token stream into a parse tree, which represents the syntactic structure of the code based on the language's grammar rules.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- The parser applies the grammar rules specified in a formal notation like BNF (Backus-Naur Form) or EBNF (Extended Backus-Naur Form).\n",
    "- If it encounters a sequence of tokens that doesn't conform to the grammar, a syntax error is produced.\n",
    "\n",
    "### 4. Semantic Analysis\n",
    "#### Objective:\n",
    "To perform checks that are not related to syntax, like type checking, variable binding, etc.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- The compiler verifies that the parse tree adheres to the language's semantic rules.\n",
    "- For example, it may check that variables are declared before use, that functions are called with the correct number of arguments, etc.\n",
    "\n",
    "### 5. Intermediate Code Generation\n",
    "#### Objective:\n",
    "To convert the semantically correct parse tree into an intermediate code that serves as an abstraction over the target machine code.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- This intermediate code is usually platform-independent.\n",
    "- It allows for further optimization without having to deal with the specifics of the target architecture.\n",
    "\n",
    "### 6. Optimization\n",
    "#### Objective:\n",
    "To optimize the intermediate code for performance, memory usage, or other criteria.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- The compiler applies various optimization techniques to eliminate redundant code, improve data flow, etc.\n",
    "\n",
    "### 7. Code Generation\n",
    "#### Objective:\n",
    "To convert the optimized intermediate code into the target machine code or assembly language.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- The code generator produces the final output based on the specifics of the target architecture.\n",
    "\n",
    "### 8. Linking\n",
    "#### Objective:\n",
    "To combine multiple machine code files (possibly from different sources) into a single executable.\n",
    "\n",
    "#### How it Works:\n",
    "\n",
    "- The linker resolves external references, assigns final memory addresses to functions and variables, and produces a single executable or library.\n",
    "\n",
    "This gives you a broad overview of the entire process. Each of these stages can be quite complex and may involve many sub-steps. But this should provide a reasonable high-level understanding of what it takes to get from source code to machine code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compilation vs Interpretation vs Hybrid Approach (review)\n",
    "\n",
    "Let's review the concepts of compilation vs interpretation vs hybrid approach from previous lessons.\n",
    "\n",
    "We already know that a compiler is a program that translates source code into machine code. But there are other ways to translate source code into machine code, such as interpretation and hybrid approaches.\n",
    "\n",
    "### Compilation\n",
    "\n",
    "In compilation, the entire source code is converted into machine code at once. The resulting machine code is stored as a separate file, which is executed later. This approach is used by languages like C, C++, Java, etc.\n",
    "\n",
    "### Interpretation\n",
    "\n",
    "In interpretation, the source code is converted into machine code one line at a time. The machine code is executed immediately after it is generated. This approach is used by languages like Python, JavaScript, etc.\n",
    "\n",
    "### Hybrid Approach\n",
    "\n",
    "In the hybrid approach, the source code is converted into intermediate code, which is then executed by an interpreter. This approach is used by languages like C#, PHP, etc.\n",
    "\n",
    "### JIT Compilation\n",
    "\n",
    "Just-in-time (JIT) compilation is a hybrid approach that combines the speed of compilation with the flexibility of interpretation. In JIT compilation, the source code is compiled into machine code at runtime, just before executing it. This approach is used by languages like C#, Java, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract vs Concrete Syntax Trees\n",
    "\n",
    "Understanding the difference between abstract and concrete syntax is crucial for those who are interested in the design and implementation of programming languages, compilers, or interpreters.\n",
    "\n",
    "### Concrete Syntax\n",
    "Concrete syntax, often called \"surface syntax,\" refers to the literal textual or visual representation of a program. It specifies the exact sequence of characters that are valid in a program. This is what programmers actually write in their code editors.\n",
    "\n",
    "For example, consider the following Python code for calculating the factorial of a number:\n",
    "\n",
    "```python\n",
    "def factorial(n):\n",
    "    if n == 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return n * factorial(n-1)\n",
    "\n",
    "```\n",
    "The concrete syntax involves everything: the layout of the code, the braces, the indentation, the keywords, etc. Concrete syntax is what is read and produced by the lexical and syntactic analysis phases of a compiler or interpreter.\n",
    "\n",
    "### Abstract Syntax\n",
    "Abstract syntax, on the other hand, represents the hierarchical and structural view of a program, abstracting away many of the textual details. In this form, the focus is on the relationships between the elements, rather than on how they are specifically notated.\n",
    "\n",
    "For the above Python example, an abstract syntax tree (AST) might represent the program like so:\n",
    "\n",
    "\n",
    "- A `function definition` node with the name \"factorial\" and argument \"n\"\n",
    "   - An `if-else` node\n",
    "      - A `condition` node specifying that `n == 0`\n",
    "         - A `return` node with value `1`\n",
    "      \n",
    "<li>An `else` node\n",
    "- A `return` node\n",
    "   - An `expression` node that multiplies `n` by `factorial(n-1)`\n",
    "\n",
    "In abstract syntax, details like the placement of parentheses, specific keyword usage, and other syntactic sugar may be irrelevant, as they are not necessary for understanding the program's structure or meaning.\n",
    "\n",
    "### Why Both Are Important\n",
    "Both concrete and abstract syntax have their roles:\n",
    "\n",
    "\n",
    "- **Concrete Syntax**: Important for writing, reading, and maintaining programs. It's what developers interact with directly.\n",
    "- **Abstract Syntax**: Critical for program analysis, optimization, and transformation, often serving as an intermediary representation of the program within compilers and other tools.\n",
    "\n",
    "In programming language theory and in the construction of compilers and interpreters, it's common to convert a program's concrete syntax into its abstract syntax as an early step. This abstract representation is often easier to work with when it comes to tasks like semantic analysis, optimization, and code generation.\n",
    "\n",
    "Understanding the abstract syntax can also be crucial for tasks like programmatic code manipulation, refactoring, and analysis, which is why many tools and libraries offer ways to work directly with the abstract syntax tree of a program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Typical methods for concrete syntax specifications\n",
    "\n",
    "The specification of concrete syntax for programming languages involves formal methods that provide a precise and unambiguous way to define the rules that determine how programs can be written in that language. Here are some of the most commonly used methods for specifying the concrete syntax:\n",
    "\n",
    "### Backus-Naur Form (BNF) and Extended Backus-Naur Form (EBNF)\n",
    "Backus-Naur Form (BNF) and its extension, Extended Backus-Naur Form (EBNF), are among the most widely used notations for specifying the syntax of programming languages. BNF was initially developed to describe the syntax of the Algol 60 programming language.\n",
    "\n",
    "A BNF specification describes a language in terms of production rules, which define how a sequence of tokens can be generated from a given symbol (called a non-terminal).\n",
    "\n",
    "For example, a simplified BNF-like specification for a basic arithmetic expression might look something like this:\n",
    "\n",
    "```bash\n",
    "<expression> ::= <term> \"+\" <term>\n",
    "               | <term> \"-\" <term>\n",
    "               | <term>\n",
    "\n",
    "<term>       ::= <factor> \"*\" <factor>\n",
    "               | <factor> \"/\" <factor>\n",
    "               | <factor>\n",
    "\n",
    "<factor>     ::= \"(\" <expression> \")\"\n",
    "               | <number>\n",
    "\n",
    "<number>     ::= \"0\" | \"1\" | \"2\" | ... | \"9\"\n",
    "\n",
    "```\n",
    "In EBNF, you can introduce more advanced constructs, like optional elements, repetitions, and groupings, making it more expressive than the original BNF.\n",
    "\n",
    "### Regular Expressions\n",
    "Regular expressions are often used in the lexical analysis phase of a compiler to specify the format of tokens such as identifiers, numbers, and special symbols. For example, a regular expression for a basic identifier in many programming languages might be `[a-zA-Z_][a-zA-Z_0-9]*`.\n",
    "\n",
    "### Syntax Diagrams (Railroad Diagrams)\n",
    "Syntax diagrams, also known as railroad diagrams, provide a graphical representation of the syntax rules. In these diagrams, each rule is represented as a path, often with forks and loops to indicate optional or repeated elements.\n",
    "\n",
    "Syntax diagrams are quite intuitive to understand but are not as concise as BNF or EBNF for complex languages.\n",
    "\n",
    "### Augmented Parsing Methods\n",
    "More advanced parsing techniques, like LR (Left-to-right, Rightmost derivation), LALR (Look-Ahead LR), and LL (Left-to-right, Leftmost derivation) grammars, are also used to describe syntax rules. These methods are more machine-oriented and are used by parser generators like YACC (Yet Another Compiler-Compiler) and ANTLR (Another Tool for Language Recognition) to produce parsers from a given grammar.\n",
    "\n",
    "### Attribute Grammars\n",
    "Attribute grammars extend the concept of grammars like BNF by adding semantic rules to the syntax rules. Each syntax rule is associated with a set of attributes and equations that compute the attributes. Attribute grammars are powerful tools for specifying both syntax and some aspects of semantics.\n",
    "\n",
    "These are just a few of the most common methods. Each method has its own set of advantages and disadvantages. Some are more intuitive and human-readable, while others are more machine-oriented and easier to parse. Some are more expressive, while others are more concise. Some are more suitable for specifying syntax, while others can also be used to specify semantics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BNF: Backus-Naur Form\n",
    "\n",
    "The Backus-Naur Form (BNF) is most accurately described as a context-free grammar (CFG). In formal language theory, context-free grammars are used to generate context-free languages. These grammars are powerful enough to describe the syntactic structure of most programming languages.\n",
    "\n",
    "### Context-Free Grammars (CFG)\n",
    "In a context-free grammar, the production rules specify that a single non-terminal can be replaced by a sequence of terminals and/or non-terminals. The \"context-free\" part means that the replacement of a non-terminal does not depend on its surrounding symbols (its \"context\").\n",
    "\n",
    "A context-free grammar is typically defined as a 4-tuple <math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mo stretchy=\"false\">(</mo><mi>N</mi><mo separator=\"true\">,</mo><mi mathvariant=\"normal\">Σ</mi><mo separator=\"true\">,</mo><mi>P</mi><mo separator=\"true\">,</mo><mi>S</mi><mo stretchy=\"false\">)</mo></mrow><annotation encoding=\"application/x-tex\">(N, \\Sigma, P, S)</annotation></semantics></math><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"strut\" style=\"height: 1em; vertical-align: -0.25em;\">(<span class=\"mord mathnormal\" style=\"margin-right: 0.10903em;\">N,<span class=\"mspace\" style=\"margin-right: 0.1667em;\">Σ,<span class=\"mspace\" style=\"margin-right: 0.1667em;\"><span class=\"mord mathnormal\" style=\"margin-right: 0.13889em;\">P,<span class=\"mspace\" style=\"margin-right: 0.1667em;\"><span class=\"mord mathnormal\" style=\"margin-right: 0.05764em;\">S), where:\n",
    "\n",
    "\n",
    "- N\n",
    "N\n",
    "N is a set of non-terminal symbols.\n",
    "- Σ\n",
    "\\Sigma\n",
    "Σ is a set of terminal symbols (disjoint from\n",
    "N\n",
    "N\n",
    "N).\n",
    "- P\n",
    "P\n",
    "P is a set of production rules, each transforming a single non-terminal into a sequence of terminals and/or non-terminals.\n",
    "- S\n",
    "S\n",
    "S is the start symbol, an element of\n",
    "N\n",
    "N\n",
    "N.\n",
    "\n",
    "### Example\n",
    "A simplified BNF-like representation of an arithmetic expression could be:\n",
    "\n",
    "```bash\n",
    "<expression> ::= <term> \"+\" <term>\n",
    "               | <term> \"-\" <term>\n",
    "               | <term>\n",
    "\n",
    "<term>       ::= <factor> \"*\" <factor>\n",
    "               | <factor> \"/\" <factor>\n",
    "               | <factor>\n",
    "\n",
    "<factor>     ::= \"(\" <expression> \")\"\n",
    "               | <number>\n",
    "\n",
    "<number>     ::= \"0\" | \"1\" | \"2\" | ... | \"9\"\n",
    "\n",
    "```\n",
    "In this example:\n",
    "\n",
    "\n",
    "- N\n",
    "N\n",
    "N would be {`\n",
    "`, `\n",
    "`, `\n",
    "`, `\n",
    "`}\n",
    "- Σ\n",
    "\\Sigma\n",
    "Σ would be {\"+\", \"-\", \"*\", \"/\", \"(\", \")\", \"0\", \"1\", \"2\", ..., \"9\"}\n",
    "- P\n",
    "P\n",
    "P would contain the production rules as shown in the BNF.\n",
    "- S\n",
    "S\n",
    "S would be `\n",
    "` (assuming we are interested in parsing expressions).\n",
    "\n",
    "BNF allows us to easily represent the hierarchical structure of programming constructs, making it well-suited for describing the syntax of programming languages. However, it's worth mentioning that while BNF is useful for specifying the structure of syntactically valid sentences, it does not capture their semantics—that is, their meaning or behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-terminal symbols\n",
    "\n",
    "Non-terminal symbols, also known as non-terminals, are symbols used in the production rules of a formal grammar, such as a context-free grammar, to define the structure of valid strings in a language. These symbols are placeholders for patterns of terminal symbols that can generate valid strings or sequences. In essence, they serve as the variables in the grammar.\n",
    "\n",
    "### Characteristics of Non-Terminals\n",
    "\n",
    "- **Abstract Representations**: Non-terminals represent abstract syntactic categories like \"expression,\" \"statement,\" or \"identifier,\" that are eventually replaced by terminal symbols to produce valid strings in the language.\n",
    "- **Rule Definitions**: Non-terminals appear on the left-hand side of production rules, defining how they can be expanded into sequences of terminal and/or other non-terminal symbols.\n",
    "- **Recursive Definitions**: Non-terminals can be defined in terms of themselves, allowing for recursive structures. For example, in arithmetic expressions, an \"expression\" can contain smaller \"expressions.\"\n",
    "- **Not in Output**: Non-terminal symbols do not appear in the valid sentences (or strings) of the language. They serve only as intermediate symbols during the derivation process.\n",
    "- **Not Concrete**: Unlike terminal symbols, which are the actual characters or tokens you would see in the source code, non-terminals are abstract and not directly visible in the language.\n",
    "\n",
    "### Example in Context-Free Grammar\n",
    "In a grammar specified in Backus-Naur Form (BNF) for simple arithmetic expressions, you might have:\n",
    "\n",
    "```bash\n",
    "<expression> ::= <term> \"+\" <term> | <term> \"-\" <term> | <term>\n",
    "<term>       ::= <factor> \"*\" <factor> | <factor> \"/\" <factor> | <factor>\n",
    "<factor>     ::= \"(\" <expression> \")\" | <number>\n",
    "<number>     ::= \"0\" | \"1\" | \"2\" | ... | \"9\"\n",
    "\n",
    "```\n",
    "Here, `<expression>`, `<term>`, `<factor>`, and `<number>` are non-terminal symbols. They help to define the structure and hierarchy of valid arithmetic expressions. On the other hand, \"+\", \"-\", \"*\", \"/\", \"(\", \")\", \"0\", \"1\", \"2\", ..., \"9\" are terminal symbols.\n",
    "\n",
    "In summary, non-terminals are the building blocks of a formal grammar that help define the syntactic structure of a language. They capture the hierarchical and often recursive relationships between different elements of the syntax.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attribute grammars\n",
    "\n",
    "Attribute grammars extend the concept of context-free grammars by adding additional information, called \"attributes,\" to the grammar symbols (both terminals and non-terminals). These attributes help in capturing more aspects of the language's semantics, beyond what can be captured by syntax alone. Attribute grammars are particularly useful for semantic analysis, type checking, and other compile-time operations.\n",
    "\n",
    "### Key Components of Attribute Grammars\n",
    "\n",
    "- **Attributes**: These are properties associated with grammar symbols (terminals and non-terminals). For example, an attribute might represent the data type of an expression, the location of a variable declaration, or the value of a constant expression.\n",
    "- **Attribute Rules**: Also known as \"semantic rules,\" these are equations or functions that define how attributes are computed. The rules are associated with the production rules of the grammar and specify how attributes of the symbols in the production are related.\n",
    "- **Attribute Dependency Graph**: This is a directed graph where nodes correspond to attribute instances and edges represent dependencies between attributes. This graph helps in understanding the order in which attributes should be evaluated.\n",
    "- **Types of Attributes**:\n",
    "   - **Synthesized Attributes**: The value of a synthesized attribute for a non-terminal is computed from the attribute values of its children in the parse tree. This is a bottom-up computation.\n",
    "   - **Inherited Attributes**: The value of an inherited attribute for a non-terminal is computed from the attribute values of its parent and/or siblings in the parse tree. This is a top-down computation.\n",
    "\n",
    "### Example\n",
    "Consider a simplified grammar for arithmetic expressions:\n",
    "\n",
    "```kotlin\n",
    "E ::= E '+' T { E.val = E1.val + T.val }\n",
    "    | T       { E.val = T.val }\n",
    "    \n",
    "T ::= T '*' F { T.val = T1.val * F.val }\n",
    "    | F       { T.val = F.val }\n",
    "    \n",
    "F ::= '(' E ')' { F.val = E.val }\n",
    "    | digit     { F.val = digit.lexval }\n",
    "\n",
    "```\n",
    "Here, `.val` is an attribute that stores the computed value of an expression, term, or factor. The attribute rules (inside the curly braces) specify how `.val` should be computed for each production rule.\n",
    "\n",
    "### Advantages and Use-Cases\n",
    "\n",
    "- **Semantic Analysis**: Attribute grammars can be used for type checking, scope resolution, and other semantic analyses.\n",
    "- **Code Generation**: They can be used to annotate a parse tree with information useful for generating intermediate or target code.\n",
    "- **Optimization**: Information computed and stored as attributes can be used for compile-time optimizations.\n",
    "- **Readability and Maintenance**: By embedding semantic rules within the grammar, attribute grammars can make the language specification more comprehensive and easier to maintain.\n",
    "- **Tool Support**: Some compiler construction tools are designed to work with attribute grammars, automating the process of attribute evaluation.\n",
    "\n",
    "Thus, attribute grammars enrich the expressiveness of context-free grammars by adding semantic information through attributes, making them a powerful tool for language specification and compiler implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unambiguous vs Ambiguous Grammars\n",
    "\n",
    "Unambiguous context-free grammars are a subset of context-free grammars. A context-free grammar is said to be unambiguous if every valid string in the language has exactly one valid leftmost derivation, or equivalently, exactly one corresponding parse tree. In simpler terms, an unambiguous grammar is one where every string generated by the grammar has only one interpretation.\n",
    "\n",
    "### Why Is Unambiguity Important?\n",
    "\n",
    "- **Simplifies Parsing**: Unambiguous grammars often lead to more efficient and simpler parsers. Ambiguous grammars usually require more complex parsing strategies and may necessitate backtracking or lookahead, which can be computationally expensive.\n",
    "- **Clear Semantics**: Unambiguity is desirable because it ensures that a string (like a program or expression) has only one interpretation. This is essential for tasks like code generation and semantic analysis.\n",
    "- **Ease of Implementation**: Compilers and interpreters are easier to implement when the underlying grammar is unambiguous, as the translation from source code to machine code (or some other target language) becomes straightforward.\n",
    "\n",
    "### Examples\n",
    "Consider the grammar for arithmetic expressions involving addition and multiplication:\n",
    "\n",
    "\n",
    "- **Ambiguous Grammar**: The following grammar is ambiguous because the expression \"a + b * c\" can be parsed in two different ways: either as \"(a + b) * c\" or as \"a + (b * c)\".\n",
    "\n",
    "```mathematica\n",
    "E → E + E | E * E | id\n",
    "\n",
    "```\n",
    "- **Unambiguous Grammar**: This modified grammar ensures that each expression has only one valid parse tree. For example, \"a + b * c\" is parsed as \"a + (b * c)\".\n",
    "\n",
    "```r\n",
    "E → E + T | T\n",
    "T → T * F | F\n",
    "F → id\n",
    "\n",
    "```\n",
    "\n",
    "### Checking for Unambiguity\n",
    "Determining whether a context-free grammar is unambiguous is undecidable in general. However, for specific classes of grammars or languages, it may be possible to prove or disprove unambiguity.\n",
    "\n",
    "### Practical Applications\n",
    "In compiler construction, efforts are often made to design unambiguous grammars for programming languages to simplify the parsing process and ensure the consistent interpretation of programs. Tools like YACC (Yet Another Compiler Compiler) or ANTLR (Another Tool for Language Recognition) often work best with unambiguous grammars and may offer ways to resolve ambiguities if they exist.\n",
    "\n",
    "In summary, an unambiguous context-free grammar ensures a one-to-one correspondence between the strings in the language and their syntactic structures, greatly simplifying parsing and semantic analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lowest level syntactic units in formal descriptions of programming languages\n",
    "\n",
    "The lowest level syntactic units in formal descriptions of programming languages are typically called \"tokens.\" These are the atomic building blocks that are produced by the lexical analysis phase (also known as \"lexing\" or \"scanning\") of a compiler or interpreter. Tokens are sequences of characters that represent a single logical unit in the source code.\n",
    "\n",
    "### Common Types of Tokens\n",
    "\n",
    "- **Keywords**: Reserved words that have special meaning in the language, like `if`, `else`, `while`, `return`, etc.\n",
    "- **Identifiers**: Names used for variables, functions, classes, and other types of symbols.\n",
    "- **Literals**: Constant values that appear directly in the source code, like integers (`42`), floating-point numbers (`3.14`), strings (`\"hello\"`), or booleans (`true`, `false`).\n",
    "- **Operators**: Symbols that represent computations like addition (`+`), subtraction (`-`), multiplication (`*`), division (`/`), and others.\n",
    "- **Punctuation**: Other syntactic markers like semicolons (`;`), commas (`,`), parentheses (`(`, `)`), braces (`{`, `}`), and brackets (`[`, `]`).\n",
    "- **Comments**: Though often ignored for the purposes of parsing the actual program, comments are usually recognized at the lexical level to be filtered out.\n",
    "\n",
    "### Tokenization Process\n",
    "During lexical analysis, the source code is read character by character, and these characters are grouped into tokens based on rules specific to the programming language. These tokens are then passed on to the next phase of the compiler (syntax analysis, commonly known as \"parsing\"), where they are assembled into a syntax tree based on the higher-level grammar of the language.\n",
    "\n",
    "### Formal Descriptions\n",
    "In formal language descriptions, tokens are often described using regular expressions or finite automata. In Backus-Naur Form (BNF) or Extended Backus-Naur Form (EBNF), tokens usually appear as terminal symbols, which are the leaves in the syntax tree.\n",
    "\n",
    "For example, a simplified EBNF rule for an integer literal in a hypothetical language might look like:\n",
    "\n",
    "```makefile\n",
    "INTEGER_LITERAL = \"0\" | [ \"-\" ], ( \"1\" | \"2\" | \"3\" | ... | \"9\" ), { \"0\" | \"1\" | ... | \"9\" } ;\n",
    "\n",
    "```\n",
    "Here, `INTEGER_LITERAL` is a token representing integer literals, and its pattern is described using a regular expression-like syntax.\n",
    "\n",
    "So, tokens are the smallest syntactic units in formal language descriptions and play a crucial role in the process of transforming a source code file into an abstract syntax tree (AST) or other internal representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abstract syntax \n",
    "\n",
    "Abstract syntax plays a vital role in the interpretation and compilation of programming languages by providing a higher-level, structural view of a program. Unlike concrete syntax, which is concerned with the textual representation of source code, abstract syntax focuses on the program's hierarchical organization and logical constructs, devoid of any textual formatting or syntactic sugar. Here are some of the key roles that abstract syntax serves:\n",
    "\n",
    "### Key Roles of Abstract Syntax\n",
    "\n",
    "- **Simplification**: By eliminating the details of the textual representation, abstract syntax simplifies the code, making it easier to perform subsequent analyses and transformations.\n",
    "- **Semantic Analysis**: Abstract syntax trees (ASTs) or similar structures provide a clean platform for conducting semantic checks like type checking, scope resolution, and variable binding, which are essential for program correctness.\n",
    "- **Code Generation**: Compilers often use the abstract syntax as a stepping stone to generate intermediate code or direct machine code. The AST or other abstract representations make it straightforward to translate high-level constructs into lower-level instructions.\n",
    "- **Optimization**: The abstract syntax representation is amenable to various optimizations like constant folding, dead code elimination, and loop unrolling. Such optimizations are easier to perform on a simplified, structured representation than on raw source code.\n",
    "- **Portability**: Since abstract syntax is a high-level representation, tools and technologies that operate on this level can often be reused across different languages or platforms, provided they share similar constructs.\n",
    "- **Tooling**: Tools like syntax highlighters, linters, and refactoring tools often work more reliably when they operate on a language's abstract rather than concrete syntax. This is because the abstract syntax captures the semantic essence of a program, making it easier to analyze code meaningfully.\n",
    "- **Language Extensions and Transformations**: Abstract syntax provides a flexible platform for language research and development. New language features can be prototyped and implemented at the abstract syntax level before they are integrated into the concrete syntax.\n",
    "\n",
    "### Examples\n",
    "Consider a simple arithmetic expression like `2 + 3 * 4`. While its concrete syntax involves the exact sequence of numbers, spaces, and operators, its abstract syntax might represent it as a tree where the '+' and '*' operators are internal nodes and the numbers are leaves. This hierarchical structure makes it clear that multiplication has higher precedence over addition.\n",
    "\n",
    "### Contrast with Concrete Syntax\n",
    "While concrete syntax deals with the program text and is vital for parsing, the abstract syntax is crucial for almost every subsequent phase in a language processing pipeline, whether it's a compiler, interpreter, or other kinds of language analysis tools. It offers a more \"semantic\" view of the program, focusing on what the program is intended to do rather than how it is written.\n",
    "\n",
    "Again, abstract syntax provides a structured and simplified representation of a program, making it easier to analyze, manipulate, and translate the code. It plays a critical role in the internal workings of compilers and interpreters and is fundamental for program analysis and transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar for Arithmetic Expressions\n",
    "\n",
    "Below is a simple example of a formal grammar in Backus-Naur Form (BNF) that can be used for arithmetic expressions involving addition, subtraction, multiplication, and division, as well as parentheses for grouping. This example assumes that the language contains integer literals.\n",
    "\n",
    "```bash\n",
    "<expression> ::= <term> { (\"+\" | \"-\") <term> }\n",
    "\n",
    "<term>       ::= <factor> { (\"*\" | \"/\") <factor> }\n",
    "\n",
    "<factor>     ::= \"(\" <expression> \")\" | <integer>\n",
    "\n",
    "<integer>    ::= \"0\" | \"1\" | \"2\" | ... | \"9\" { \"0\" | \"1\" | ... | \"9\" }\n",
    "\n",
    "```\n",
    "### Explanation\n",
    "\n",
    "- `\n",
    "`: An expression is a `\n",
    "` possibly followed by a series of additions or subtractions (`+` or `-`) of other `\n",
    "`s.\n",
    "- `\n",
    "`: A term is a `\n",
    "` possibly followed by a series of multiplications or divisions (`*` or `/`) of other `\n",
    "`s.\n",
    "- `\n",
    "`: A factor can be either another `\n",
    "` enclosed in parentheses or an `\n",
    "`.\n",
    "- `\n",
    "`: An integer is a sequence of digits, starting with a non-zero digit.\n",
    "\n",
    "This is a simple example and doesn't cover many other features you might find in a real programming language, such as floating-point numbers, unary operators, or other built-in functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse tree from grammar\n",
    "\n",
    "Creating a parse tree from a formal grammar involves taking an input string and breaking it down into its constituent parts according to the rules of the grammar. For the sake of explanation, let's consider a simple arithmetic expression: `2 + 3 * 4`.\n",
    "\n",
    "### Steps to Build a Parse Tree\n",
    "\n",
    "- **Start with the root**: Begin with the start symbol of the grammar as the root of the tree. In our case, the start symbol is `\n",
    "`.\n",
    "- **Expand the root**: Apply one of the production rules for `\n",
    "` to expand the root. The rule is `\n",
    "::=\n",
    "{ (\"+\" | \"-\")\n",
    "}`. Since our expression contains a `+`, it matches this rule. So the tree will initially look something like this:\n",
    "\n",
    "```php\n",
    "/     |      \\\n",
    "+\n",
    "```\n",
    "- **Expand the terms**: Next, we focus on the `\n",
    "` non-terminals. According to our grammar, a `\n",
    "` is a `\n",
    "` followed by zero or more multiplication (`*`) or division (`/`) operators and additional `\n",
    "`s. Our terms are `2` and `3 * 4`, which don't have additional multiplication or division operations for the first term (`2`). The second term (`3 * 4`) does include multiplication.\n",
    "\n",
    "So our tree becomes:\n",
    "\n",
    "```php\n",
    "/      |       \\\n",
    "+\n",
    "/                   /    \\    \\\n",
    "\n",
    "*\n",
    "|                      |           |\n",
    "\n",
    "\n",
    "|                      |           |\n",
    "   2                      3           4\n",
    "\n",
    "```\n",
    "- **Finalize the tree**: All non-terminals have been replaced by terminals (actual numbers or operators in this case), so the parse tree is complete.\n",
    "\n",
    "### Final Parse Tree\n",
    "In the final parse tree, the leaves are the terminals: `2`, `+`, `3`, `*`, and `4`. The internal nodes are non-terminals: `<expression>`, `<term>`, and `<factor>`. The tree accurately reflects the hierarchical structure of the original expression `2 + 3 * 4`, taking into account the precedence of the `*` operator over `+`.\n",
    "\n",
    "This is a simplified example; building a parse tree programmatically would involve more complex algorithms like recursive descent parsing, or using tools like Lex/Yacc or ANTLR that generate parsers automatically based on formal grammars."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended Backus-Naur Form (EBNF)\n",
    "\n",
    "Extended Backus-Naur Form (EBNF) is an enhancement of the original Backus-Naur Form (BNF) notation for describing the grammar of programming languages. EBNF introduces syntactical sugar and additional constructs that make it more expressive, readable, and concise. Here are some of the extra features that EBNF brings compared to plain BNF:\n",
    "\n",
    "### 1. Optional Elements\n",
    "EBNF allows for optional elements using square brackets `[ ... ]`. This makes it easier to specify optional syntax components directly.\n",
    "\n",
    "In BNF:\n",
    "\n",
    "```bnf\n",
    "<optional-semicolon> ::= \";\" | ε\n",
    "\n",
    "```\n",
    "In EBNF:\n",
    "\n",
    "```ebnf\n",
    "[ \";\" ]\n",
    "\n",
    "```\n",
    "### 2. Repetition (Zero or More)\n",
    "EBNF introduces a shorthand for specifying zero or more repetitions using curly brackets `{ ... }`.\n",
    "\n",
    "In BNF:\n",
    "\n",
    "```bnf\n",
    "<identifiers> ::= <identifier> | <identifier> \",\" <identifiers>\n",
    "\n",
    "```\n",
    "In EBNF:\n",
    "\n",
    "```ebnf\n",
    "<identifier> { \",\" <identifier> }\n",
    "\n",
    "```\n",
    "### 3. Alternatives\n",
    "EBNF allows for in-line grouping of alternatives using parentheses `( ... )`.\n",
    "\n",
    "In BNF:\n",
    "\n",
    "```bnf\n",
    "<expression> ::= <term> <expression-tail>\n",
    "<expression-tail> ::= \"+\" <term> <expression-tail> | \"-\" <term> <expression-tail> | ε\n",
    "\n",
    "```\n",
    "In EBNF:\n",
    "\n",
    "```ebnf\n",
    "<expression> ::= <term> { (\"+\" | \"-\") <term> }\n",
    "\n",
    "```\n",
    "### 4. Terminal Symbols\n",
    "EBNF often allows the use of terminal symbols (like literals) directly in the grammar rules, sometimes even without quotes. This improves readability.\n",
    "\n",
    "In BNF:\n",
    "\n",
    "```bnf\n",
    "<plus-sign> ::= \"+\"\n",
    "\n",
    "```\n",
    "In EBNF:\n",
    "\n",
    "```ebnf\n",
    "\"+\"\n",
    "\n",
    "```\n",
    "### 5. Special Sequences\n",
    "EBNF sometimes includes special sequences for more advanced pattern matching, often in the form of regular expressions or other string patterns.\n",
    "\n",
    "### 6. Comments and Annotations\n",
    "EBNF often supports comments and annotations, which makes the grammar specification more understandable.\n",
    "\n",
    "### 7. Exception Mechanism\n",
    "Some variants of EBNF introduce an exception mechanism with `-` to indicate that certain sequences should not be matched. This feature is less common but can be useful.\n",
    "\n",
    "### Summary\n",
    "EBNF aims to improve upon BNF by adding more expressive power and reducing verbosity. These enhancements make EBNF more suitable for complex grammars and improve the readability and maintainability of the grammar specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grammar for arithmetic expressions in EBNF\n",
    "\n",
    "In Extended Backus-Naur Form (EBNF), the grammar for arithmetic expressions involving addition, subtraction, multiplication, division, and parentheses can be more concisely expressed with additional syntactic sugar. Here's how you could define such a grammar:\n",
    "\n",
    "```ebnf\n",
    "expression = term { (\"+\" | \"-\") , term };\n",
    "term       = factor { (\"*\" | \"/\") , factor };\n",
    "factor     = integer | \"(\" , expression , \")\" ;\n",
    "integer    = digit , { digit };\n",
    "digit      = \"0\" | \"1\" | \"2\" | \"3\" | \"4\" | \"5\" | \"6\" | \"7\" | \"8\" | \"9\";\n",
    "\n",
    "```\n",
    "### Explanation\n",
    "\n",
    "- `expression`: An expression is a `term` followed by zero or more additions (`+`) or subtractions (`-`) with other `term`s.\n",
    "- `term`: A term is a `factor` followed by zero or more multiplications (`*`) or divisions (`/`) with other `factor`s.\n",
    "- `factor`: A factor can either be an `integer` or an `expression` enclosed in parentheses.\n",
    "- `integer`: An integer is a sequence of one or more `digit`s.\n",
    "- `digit`: A digit can be any single decimal number from 0 to 9.\n",
    "\n",
    "As you can see, EBNF allows us to use repetition `{ ... }`, alternatives `( ... | ... )`, and optional elements `[ ... ]` more directly than standard BNF, making the grammar shorter and more readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dangling else problem\n",
    "\n",
    "The \"dangling else\" problem is a classic issue in the syntax of programming languages that arises with conditional statements like `if-else`. The problem occurs when an `if-else` statement is nested inside another `if` statement without an accompanying `else`. This creates ambiguity in determining which `if` statement the `else` is supposed to be associated with.\n",
    "\n",
    "### Example in C-style Syntax\n",
    "Consider the following code snippet:\n",
    "\n",
    "```c\n",
    "if (condition1)\n",
    "    if (condition2)\n",
    "        doSomething();\n",
    "    else\n",
    "        doSomethingElse();\n",
    "\n",
    "```\n",
    "Here, it's ambiguous whether the `else` belongs to the first `if` or the second `if`. Different associations produce different meanings:\n",
    "\n",
    "\n",
    "- The `else` belongs to the inner `if` (common interpretation):\n",
    "\n",
    "```c\n",
    "if (condition1) {\n",
    "    if (condition2) {\n",
    "        doSomething();\n",
    "    } else {\n",
    "        doSomethingElse();\n",
    "    }\n",
    "}\n",
    "\n",
    "```\n",
    "- The `else` belongs to the outer `if`:\n",
    "\n",
    "```c\n",
    "if (condition1) {\n",
    "    if (condition2) {\n",
    "        doSomething();\n",
    "    }\n",
    "} else {\n",
    "    doSomethingElse();\n",
    "}\n",
    "\n",
    "```\n",
    "\n",
    "### How Programming Languages Deal With It\n",
    "Programming languages generally adopt one of two approaches to resolve this ambiguity:\n",
    "\n",
    "\n",
    "- **Closest `if` Rule**: Most languages like C, C++, Java, and Python associate each `else` with the closest preceding `if` that lacks an `else`. This is generally the innermost `if`.\n",
    "- **Explicit Scoping**: Some languages like Ada require explicit scoping (begin/end or similar constructs) to eliminate such ambiguities.\n",
    "\n",
    "### Formal Grammar Solution\n",
    "In formal grammars, this issue can be addressed by making the association explicit. For example, in a BNF-like notation, you might have:\n",
    "\n",
    "```bnf\n",
    "<statement> ::= \"if\" <condition> \"then\" <statement> \"else\" <statement>\n",
    "             | \"if\" <condition> \"then\" <statement>\n",
    "             | <other-statements>\n",
    "\n",
    "```\n",
    "In this grammar, an `else` can only be part of an `if` that directly precedes it, thereby eliminating the ambiguity by adhering to the closest `if` rule.\n",
    "\n",
    "The \"dangling else\" problem serves as a case study of how ambiguity in formal grammars can lead to challenges in parsing and understanding programs, and it illustrates the importance of clear syntax rules in programming language design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PAM - Precedence Associativity and Matching(Membership)\n",
    "\n",
    "In the context of programming language grammars, PAM usually refers to \"Precedence, Associativity, and Membership,\" which are attributes that help define the behavior and structure of operators and expressions in a programming language. These attributes help resolve ambiguities in the grammar and guide the construction of parse trees. Let's take a closer look at each:\n",
    "\n",
    "### 1. Precedence\n",
    "Precedence rules define the order in which operators are evaluated when an expression involves multiple operators. For example, in many programming languages, multiplication and division have higher precedence than addition and subtraction.\n",
    "\n",
    "In the expression `2 + 3 * 4`, the multiplication (`*`) is performed before the addition (`+`) because it has higher precedence, making the evaluation equal to `2 + 12 = 14`.\n",
    "\n",
    "### 2. Associativity\n",
    "Associativity rules define the order in which operators of the same precedence level are evaluated. Operators can be left-associative, right-associative, or non-associative.\n",
    "\n",
    "\n",
    "- **Left-associative**: Operators are evaluated from left to right. For example, in the expression `2 - 1 - 1`, the subtraction is left-associative, so the expression is evaluated as `(2 - 1) - 1 = 0`.\n",
    "- **Right-associative**: Operators are evaluated from right to left. Exponentiation is often right-associative. For example, in the expression `2 ^ 3 ^ 2`, it's evaluated as `2 ^ (3 ^ 2) = 512` (assuming `^` represents exponentiation).\n",
    "- **Non-associative**: The operator does not associate with others of its kind. For example, the equality operator `==` in some languages is non-associative, making expressions like `a == b == c` illegal.\n",
    "\n",
    "### 3. Membership\n",
    "Membership defines which category or group an operator belongs to, which in turn dictates its precedence and associativity. For example, the `+` and `-` operators might belong to a group of \"additive operators,\" while `*` and `/` belong to a group of \"multiplicative operators.\"\n",
    "\n",
    "In formal grammars, you often specify precedence, associativity, and membership rules to disambiguate expressions. Tools like Yacc or Bison allow you to specify these rules explicitly, helping the generated parser to correctly interpret the language's syntax."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
